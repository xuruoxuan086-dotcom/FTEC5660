{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "RRbStil_qkQc",
        "kCENjOq6owDd"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 2"
      ],
      "metadata": {
        "id": "tFaf7VErZ1Bf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up"
      ],
      "metadata": {
        "id": "I3g3k3W-qfAv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing packages"
      ],
      "metadata": {
        "id": "6vsESFZylO6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests PyPDF2 gdown\n",
        "!pip install 'markitdown[pdf]'\n",
        "!pip install langchain_mcp_adapters langchain_google_genai langchain-openai"
      ],
      "metadata": {
        "id": "Hrdfpmv9nMpw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "969178e6-b6a6-401c-905a-00bc0a6b4741",
        "collapsed": true
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.12/dist-packages (5.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2026.1.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from gdown) (4.13.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from gdown) (3.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from gdown) (4.67.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (2.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->gdown) (4.15.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "Collecting markitdown[pdf]\n",
            "  Downloading markitdown-0.1.5-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (4.13.5)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (3.4.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (0.7.1)\n",
            "Collecting magika~=0.6.1 (from markitdown[pdf])\n",
            "  Downloading magika-0.6.3-py3-none-manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
            "Collecting markdownify (from markitdown[pdf])\n",
            "  Downloading markdownify-1.2.2-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from markitdown[pdf]) (2.32.4)\n",
            "Collecting pdfminer-six>=20251230 (from markitdown[pdf])\n",
            "  Downloading pdfminer_six-20260107-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting pdfplumber>=0.11.9 (from markitdown[pdf])\n",
            "  Downloading pdfplumber-0.11.9-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown[pdf]) (8.3.1)\n",
            "Collecting onnxruntime>=1.17.0 (from magika~=0.6.1->markitdown[pdf])\n",
            "  Downloading onnxruntime-1.24.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown[pdf]) (2.0.2)\n",
            "Requirement already satisfied: python-dotenv>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from magika~=0.6.1->markitdown[pdf]) (1.2.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer-six>=20251230->markitdown[pdf]) (43.0.3)\n",
            "Collecting pdfminer-six>=20251230 (from markitdown[pdf])\n",
            "  Downloading pdfminer_six-20251230-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber>=0.11.9->markitdown[pdf]) (11.3.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber>=0.11.9->markitdown[pdf])\n",
            "  Downloading pypdfium2-5.5.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (68 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m68.1/68.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->markitdown[pdf]) (2.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->markitdown[pdf]) (4.15.0)\n",
            "Requirement already satisfied: six<2,>=1.15 in /usr/local/lib/python3.12/dist-packages (from markdownify->markitdown[pdf]) (1.17.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->markitdown[pdf]) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->markitdown[pdf]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->markitdown[pdf]) (2026.1.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer-six>=20251230->markitdown[pdf]) (2.0.0)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (25.12.19)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (26.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (5.29.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (1.14.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer-six>=20251230->markitdown[pdf]) (3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.17.0->magika~=0.6.1->markitdown[pdf]) (1.3.0)\n",
            "Downloading magika-0.6.3-py3-none-manylinux_2_28_x86_64.whl (15.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfplumber-0.11.9-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20251230-py3-none-any.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading markdownify-1.2.2-py3-none-any.whl (15 kB)\n",
            "Downloading markitdown-0.1.5-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.4/63.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.24.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-5.5.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, onnxruntime, markdownify, pdfminer-six, magika, pdfplumber, markitdown\n",
            "Successfully installed magika-0.6.3 markdownify-1.2.2 markitdown-0.1.5 onnxruntime-1.24.2 pdfminer-six-20251230 pdfplumber-0.11.9 pypdfium2-5.5.0\n",
            "Collecting langchain_mcp_adapters\n",
            "  Downloading langchain_mcp_adapters-0.2.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting langchain_google_genai\n",
            "  Downloading langchain_google_genai-4.2.1-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.1.10-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain_mcp_adapters) (1.2.15)\n",
            "Requirement already satisfied: mcp>=1.9.2 in /usr/local/lib/python3.12/dist-packages (from langchain_mcp_adapters) (1.26.0)\n",
            "Requirement already satisfied: typing-extensions>=4.14.0 in /usr/local/lib/python3.12/dist-packages (from langchain_mcp_adapters) (4.15.0)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain_google_genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.56.0 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (1.64.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain_google_genai) (2.12.3)\n",
            "Requirement already satisfied: openai<3.0.0,>=2.20.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (2.23.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (4.12.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.47.0 in /usr/local/lib/python3.12/dist-packages (from google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2.47.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.28.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2.32.4)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (9.1.4)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (15.0.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.3.1)\n",
            "Requirement already satisfied: aiohttp>=3.10.11 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain_google_genai) (3.13.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (0.7.6)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (26.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (6.0.3)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (0.14.1)\n",
            "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.4.3)\n",
            "Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (4.26.0)\n",
            "Requirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (2.13.1)\n",
            "Requirement already satisfied: pyjwt>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (2.11.0)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.0.22)\n",
            "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (3.2.0)\n",
            "Requirement already satisfied: starlette>=0.27 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.52.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.4.2)\n",
            "Requirement already satisfied: uvicorn>=0.31.1 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.9.2->langchain_mcp_adapters) (0.41.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (0.13.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain-openai) (4.67.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain_google_genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->langchain_google_genai) (2.41.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10.11->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.22.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (3.11)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain_mcp_adapters) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain_mcp_adapters) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.9.2->langchain_mcp_adapters) (0.30.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (1.0.0)\n",
            "Requirement already satisfied: xxhash>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (3.6.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_mcp_adapters) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings>=2.5.2->mcp>=1.9.2->langchain_mcp_adapters) (1.2.1)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (43.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (2.5.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.31.1->mcp>=1.9.2->langchain_mcp_adapters) (8.3.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (2.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain_google_genai) (0.6.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=3.4.0->pyjwt[crypto]>=2.10.1->mcp>=1.9.2->langchain_mcp_adapters) (3.0)\n",
            "Downloading langchain_mcp_adapters-0.2.1-py3-none-any.whl (22 kB)\n",
            "Downloading langchain_google_genai-4.2.1-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-1.1.10-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: filetype, langchain-openai, langchain_mcp_adapters, langchain_google_genai\n",
            "Successfully installed filetype-1.2.0 langchain-openai-1.1.10 langchain_google_genai-4.2.1 langchain_mcp_adapters-0.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a Colab Secret named `VERTEX_API_KEY`.\n",
        "\n",
        "\n",
        "1.   Look for the key icon on the left panel of your colab.\n",
        "2.   Under `Name`, create `VERTEX_API_KEY`.\n",
        "3. Copy your key to `Value`.\n",
        "\n",
        "If you cannot use VERTEX_API_KEY, you can use deepseek models via `DEEPSEEK_API_KEY`. It does not affect your score.\n",
        "\n"
      ],
      "metadata": {
        "id": "BUav-7KdaY_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GEMINI_VERTEX_API_KEY = userdata.get('VERTEX_API_KEY')\n",
        "# DEEPSEEK_API_KEY = userdata.get('DEEPSEEK_API_KEY')"
      ],
      "metadata": {
        "id": "ueILmCPHci9v"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download sample CVs"
      ],
      "metadata": {
        "id": "RRbStil_qkQc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading sample_cv.pdf\n",
        "The codes below download the sample CV\n"
      ],
      "metadata": {
        "id": "kCENjOq6owDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gdown\n",
        "\n",
        "folder_id = \"1adYKq7gSSczFP3iikfA8Er-HSZP6VM7D\"\n",
        "folder_url = f\"https://drive.google.com/drive/folders/{folder_id}\"\n",
        "\n",
        "output_dir = \"downloaded_cvs\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "gdown.download_folder(\n",
        "    url=folder_url,\n",
        "    output=output_dir,\n",
        "    quiet=False,\n",
        "    use_cookies=False\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kCCp8DwPF4L",
        "outputId": "94b9ffe4-4668-4a50-e6db-c044c1ade2ef"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file 1NR1RUKx4GyM7QOBxKXkfh4e8jUkxFCsp CV_1.pdf\n",
            "Processing file 16lrd-uO8AAnCnv7UG9Rs_Nk6SUu0Iwbs CV_2.pdf\n",
            "Processing file 15hVEuBan_EKhEty2aZBd6rcpDpP4o7Vr CV_3.pdf\n",
            "Processing file 1Y2w_mAUEhg4vZBdvvR-0n3Jf2mKuGDRk CV_4.pdf\n",
            "Processing file 1PLwkva-pdua6ZVvmLg9mxHeljq9D8C_C CV_5.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1NR1RUKx4GyM7QOBxKXkfh4e8jUkxFCsp\n",
            "To: /content/downloaded_cvs/CV_1.pdf\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 147k/147k [00:00<00:00, 68.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16lrd-uO8AAnCnv7UG9Rs_Nk6SUu0Iwbs\n",
            "To: /content/downloaded_cvs/CV_2.pdf\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 75.1k/75.1k [00:00<00:00, 66.9MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15hVEuBan_EKhEty2aZBd6rcpDpP4o7Vr\n",
            "To: /content/downloaded_cvs/CV_3.pdf\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72.0k/72.0k [00:00<00:00, 40.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Y2w_mAUEhg4vZBdvvR-0n3Jf2mKuGDRk\n",
            "To: /content/downloaded_cvs/CV_4.pdf\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73.3k/73.3k [00:00<00:00, 69.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PLwkva-pdua6ZVvmLg9mxHeljq9D8C_C\n",
            "To: /content/downloaded_cvs/CV_5.pdf\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97.9k/97.9k [00:00<00:00, 46.8MB/s]\n",
            "Download completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['downloaded_cvs/CV_1.pdf',\n",
              " 'downloaded_cvs/CV_2.pdf',\n",
              " 'downloaded_cvs/CV_3.pdf',\n",
              " 'downloaded_cvs/CV_4.pdf',\n",
              " 'downloaded_cvs/CV_5.pdf']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "#  Load and display all CV PDFs in order\n",
        "# =====================================================\n",
        "import os\n",
        "from markitdown import MarkItDown\n",
        "\n",
        "cv_dir = \"downloaded_cvs\"\n",
        "\n",
        "# Initialize MarkItDown\n",
        "md = MarkItDown(enable_plugins=False)\n",
        "\n",
        "# Collect and sort PDFs numerically\n",
        "pdf_files = sorted(\n",
        "    [f for f in os.listdir(cv_dir) if f.lower().endswith(\".pdf\")],\n",
        "    key=lambda x: int(\"\".join(filter(str.isdigit, x)))  # CV_1.pdf â†’ 1\n",
        ")\n",
        "\n",
        "all_cvs = []\n",
        "\n",
        "for pdf_name in pdf_files:\n",
        "    pdf_path = os.path.join(cv_dir, pdf_name)\n",
        "    result = md.convert(pdf_path)\n",
        "\n",
        "    all_cvs.append({\n",
        "        \"file\": pdf_name,\n",
        "        \"text\": result.text_content\n",
        "    })\n",
        "\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"ğŸ“„ {pdf_name}\")\n",
        "    print(\"=\" * 80)\n",
        "    print(result.text_content)\n",
        "    print(\"\\n\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2akmVn9LODIu",
        "outputId": "a7cd1836-2cee-467e-aff3-aa51199f4d3d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "ğŸ“„ CV_1.pdf\n",
            "================================================================================\n",
            "|     |     |     |     | John         |           | Smith        |                   |     |     |\n",
            "| --- | --- | --- | --- | ------------ | --------- | ------------ | ----------------- | --- | --- |\n",
            "|     |     |     |     | Marketing    |           | Professional |                   |     |     |\n",
            "|     |     |     |     | + Singapore, | Singapore |              | (cid:209) Kowloon |     |     |\n",
            "Experience\n",
            "|                |                  |     |          |                     |              |            |     | 2020 â€“ | Present |\n",
            "| -------------- | ---------------- | --- | -------- | ------------------- | ------------ | ---------- | --- | ------ | ------- |\n",
            "| Engineer,      | ByteDance        |     |          |                     |              |            |     |        |         |\n",
            "| â€¢ Worked       | in a fast-paced, |     | global   | technology          | environment. |            |     |        |         |\n",
            "| â€¢ Collaborated | across           |     | teams to | support large-scale |              | platforms. |     |        |         |\n",
            "â€¢ Applied analytical and problem-solving skills in production systems.\n",
            "Education\n",
            "| McGill   | University |       |              |     |     |     |     | Graduated | 2009 |\n",
            "| -------- | ---------- | ----- | ------------ | --- | --- | --- | --- | --------- | ---- |\n",
            "| Bachelor | of Science | (BSc) | in Marketing |     |     |     |     |           |      |\n",
            "Skills\n",
            "| Content | Creation | SEO | Social | Media |     |     |     |     |     |\n",
            "| ------- | -------- | --- | ------ | ----- | --- | --- | --- | --- | --- |\n",
            "1\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ğŸ“„ CV_2.pdf\n",
            "================================================================================\n",
            "| Minh | Pham |     |     |     |     |     |\n",
            "| ---- | ---- | --- | --- | --- | --- | --- |\n",
            "Design Professional\n",
            "| Beijing,     | China | Hong     | Kong     |               |        |              |                |\n",
            "| ------------ | ---------------- | -------- | ------------- | ------ | ------------ | -------------- |\n",
            "| Professional | Experience       |          |               |        |              |                |\n",
            "| Manager,     | BCG              |          |               |        |              | 2022 â€“ Present |\n",
            "| â€¢ Led        | cross-functional | teams on | client-facing | design | initiatives. |                |\n",
            "â€¢ Managed project timelines, deliverables, and stakeholder communication.\n",
            "| â€¢ Applied | design thinking | to business | and | strategy | problems. |             |\n",
            "| --------- | --------------- | ----------- | --- | -------- | --------- | ----------- |\n",
            "| Analyst,  | Tencent         |             |     |          |           | 2013 â€“ 2017 |\n",
            "â€¢ Conducted market and product analysis to support decision-making.\n",
            "| â€¢ Collaborated | with    | design and   | engineering | teams.      |     |     |\n",
            "| -------------- | ------- | ------------ | ----------- | ----------- | --- | --- |\n",
            "| â€¢ Produced     | reports | and insights | for senior  | leadership. |     |     |\n",
            "Education\n",
            "| BSc in         | Design  |      |     |     |     | 2011 |\n",
            "| -------------- | ------- | ---- | --- | --- | --- | ---- |\n",
            "| The University | of Hong | Kong |     |     |     |      |\n",
            "Skills\n",
            "| â€¢ UI/UX | Design |     |     |     |     |     |\n",
            "| ------- | ------ | --- | --- | --- | --- | --- |\n",
            "â€¢ Prototyping\n",
            "| â€¢ Graphic | Design |     |     |     |     |     |\n",
            "| --------- | ------ | --- | --- | --- | --- | --- |\n",
            "1\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ğŸ“„ CV_3.pdf\n",
            "================================================================================\n",
            "| Wei Zhang    |              |           |     |     |     | Munich, Germany   |\n",
            "| ------------ | ------------ | --------- | --- | --- | --- | ----------------- |\n",
            "| Consulting   | Professional |           |     |     |     | Sydney (Hometown) |\n",
            "| Professional | Experience   |           |     |     |     |                   |\n",
            "| 2013         | â€“ Present    | Engineer, | PwC |     |     |                   |\n",
            "â€¢ Supportedconsultingengagementsacrossmultipleclient\n",
            "projects.\n",
            "|     |     | â€¢ Performed | data analysis | to inform | strategic recommen- |     |\n",
            "| --- | --- | ----------- | ------------- | --------- | ------------------- | --- |\n",
            "dations.\n",
            "|     |     | â€¢ Collaborated  | with         | cross-functional | teams in | a profes- |\n",
            "| --- | --- | --------------- | ------------ | ---------------- | -------- | --------- |\n",
            "|     |     | sional services | environment. |                  |          |           |\n",
            "Education\n",
            "| 2015 |     | BSc in Consulting |          |     |     |     |\n",
            "| ---- | --- | ----------------- | -------- | --- | --- | --- |\n",
            "|      |     | University        | of Tokyo |     |     |     |\n",
            "Skills\n",
            "| Analytical |     |     | Data Analysis,       | Problem | Solving |     |\n",
            "| ---------- | --- | --- | -------------------- | ------- | ------- | --- |\n",
            "| Business   |     |     | Strategy, PowerPoint |         |         |     |\n",
            "1\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ğŸ“„ CV_4.pdf\n",
            "================================================================================\n",
            "| Rahul | Sharma |     |     |     |     |     |     |     |     |\n",
            "| ----- | ------ | --- | --- | --- | --- | --- | --- | --- | --- |\n",
            "Legal Professional\n",
            "| Singapore    | (Hometown) | | Singapore              |           | / Philippines |             |        |             |     |         |\n",
            "| ------------ | ---------- | ------------------------ | --------- | ------------- | ----------- | ------ | ----------- | --- | ------- |\n",
            "| Professional |            | Experience               |           |               |             |        |             |     |         |\n",
            "| 2021         | â€“ 2027     | Senior                   | Engineer, | Microsoft     |             |        |             |     |         |\n",
            "|              |            | â€¢ Led compliance-focused |           |               | initiatives | within | large-scale |     | techni- |\n",
            "cal teams.\n",
            "â€¢ Advisedonregulatory,legal,andriskconsiderationsforcom-\n",
            "plex systems.\n",
            "|     |     | â€¢ Worked | at the | intersection |     | of law, | technology, | and | gover- |\n",
            "| --- | --- | -------- | ------ | ------------ | --- | ------- | ----------- | --- | ------ |\n",
            "nance.\n",
            "| 2020 | â€“ 2023 | Consultant, | StartupXYZ |               |     |            |                 |     |      |\n",
            "| ---- | ------ | ----------- | ---------- | ------------- | --- | ---------- | --------------- | --- | ---- |\n",
            "|      |        | â€¢ Provided  | legal      | and strategic |     | consulting | for early-stage |     | com- |\n",
            "panies.\n",
            "|     |     | â€¢ Supported | contract | review, |     | compliance, | and operational |     | risk |\n",
            "| --- | --- | ----------- | -------- | ------- | --- | ----------- | --------------- | --- | ---- |\n",
            "management.\n",
            "|     |     | â€¢ Engaged | with | cross-functional |     | and | international | stakehold- |     |\n",
            "| --- | --- | --------- | ---- | ---------------- | --- | --- | ------------- | ---------- | --- |\n",
            "ers.\n",
            "Education\n",
            "2021\n",
            "|     |     | PhD in   | Legal      | Studies |     |     |     |     |     |\n",
            "| --- | --- | -------- | ---------- | ------- | --- | --- | --- | --- | --- |\n",
            "|     |     | Tsinghua | University |         |     |     |     |     |     |\n",
            "Skills\n",
            "|     |     | Compliance,   | Litigation, |           | Contract | Review    |     |     |     |\n",
            "| --- | --- | ------------- | ----------- | --------- | -------- | --------- | --- | --- | --- |\n",
            "|     |     | Web3, Machine |             | Learning, | Quantum  | Computing |     |     |     |\n",
            "1\n",
            "\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ğŸ“„ CV_5.pdf\n",
            "================================================================================\n",
            "| Rahul | Sharma |     |     |     |     |     |     |\n",
            "| ----- | ------ | --- | --- | --- | --- | --- | --- |\n",
            "AI Professional\n",
            "| London     | | Hong Kong | | Singapore | (Hometown) |              |               |                |               |\n",
            "| ---------- | ----------- | ----------- | ---------- | ------------ | ------------- | -------------- | ------------- |\n",
            "| Core       | Skills      |             |            | Professional | Experience    |                |               |\n",
            "| Machine    | Learning    | & AI        |            | Senior       | Engineer      |                |               |\n",
            "|            |             |             |            | EY           |               |                | Current       |\n",
            "| â€¢ Advanced | AI Systems  |             |            |              |               |                |               |\n",
            "|            |             |             |            | â€¢ Designed   | and evaluated | AI-driven      | solutions for |\n",
            "|            |             |             |            | enterprise   | clients.      |                |               |\n",
            "| â€¢ Machine  | Learning    | (ML)        |            |              |               |                |               |\n",
            "|            |             |             |            | â€¢ Applied    | ML techniques | to large-scale | business      |\n",
            "| â€¢ Natural  | Language    | Processing  | (NLP)      | problems.    |               |                |               |\n",
            "Consultant\n",
            "| Frameworks   | &   | Tools |     |             |             |          |             |\n",
            "| ------------ | --- | ----- | --- | ----------- | ----------- | -------- | ----------- |\n",
            "|              |     |       |     | StartupXYZ  |             |          | 2019 â€“ 2021 |\n",
            "| â€¢ TensorFlow |     |       |     | â€¢ Provided  | AI and data | strategy | advisory to |\n",
            "|              |     |       |     | early-stage | companies.  |          |             |\n",
            "â€¢ PyTorch\n",
            "Senior Analyst\n",
            "|     |     |     |     | DataForge |     | 2016 | â€“ Present |\n",
            "| --- | --- | --- | --- | --------- | --- | ---- | --------- |\n",
            "â€¢ Python\n",
            "|     |     |     |     | â€¢ Conducted | advanced | data analysis | and model |\n",
            "| --- | --- | --- | --- | ----------- | -------- | ------------- | --------- |\n",
            "evaluation.\n",
            "Lead Scientist\n",
            "Education\n",
            "|     |     |     |     | UrbanFlow |     |     | 2010 â€“ 2017 |\n",
            "| --- | --- | --- | --- | --------- | --- | --- | ----------- |\n",
            "PhD in Artificial Intelligence â€¢ Led research initiatives in applied AI systems.\n",
            "| University | of Tokyo |     |     |            |                    |                |     |\n",
            "| ---------- | -------- | --- | --- | ---------- | ------------------ | -------------- | --- |\n",
            "| 2012       |          |     |     | â€¢ Mentored | junior researchers | and engineers. |     |\n",
            "1\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to our MCP server\n",
        "\n",
        "Documentation about MCP: https://modelcontextprotocol.io/docs/getting-started/intro.\n",
        "\n",
        "Using MCP servers in Langchain https://docs.langchain.com/oss/python/langchain/mcp."
      ],
      "metadata": {
        "id": "VA2GvPWTQFt9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check which tools that the MCP server provide"
      ],
      "metadata": {
        "id": "5mbkH9xHXfmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import json\n",
        "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
        "\n",
        "client = MultiServerMCPClient({\n",
        "    \"social_graph\": {\n",
        "        \"transport\": \"http\",\n",
        "        \"url\": \"https://ftec5660.ngrok.app/mcp\",\n",
        "        \"headers\": {\"ngrok-skip-browser-warning\": \"true\"}\n",
        "    }\n",
        "})\n",
        "\n",
        "mcp_tools = await client.get_tools()\n",
        "for tool in mcp_tools:\n",
        "    print(tool.name)\n",
        "    print(tool.description)\n",
        "    print(tool.args)\n",
        "    print(\"\\n\\n------------------------------------------------------\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6h0311KbN9A3",
        "outputId": "16eb46a6-3a8c-4093-bded-ab804bbaf786"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "search_facebook_users\n",
            "Search for Facebook users by display name (supports partial and fuzzy matching).\n",
            "\n",
            "Args:\n",
            "    q: Search query string (case-insensitive, matches any part of display name)\n",
            "       Examples: \"John\", \"john smith\", \"Smith\"\n",
            "    limit: Maximum number of results to return (default: 20, max: 20)\n",
            "    fuzzy: Enable fuzzy matching if exact search returns no results (default: True)\n",
            "\n",
            "Returns:\n",
            "    List of user dictionaries, each containing:\n",
            "    - id (int): Unique Facebook user ID for use with get_facebook_profile()\n",
            "    - display_name (str): User's Facebook display name (may differ from legal name)\n",
            "    - city (str): Current city of residence\n",
            "    - country (str): Country of residence\n",
            "    - match_type (str): \"exact\" or \"fuzzy\" (indicates search method used)\n",
            "    \n",
            "    Returns empty list [] if no matches found.\n",
            "\n",
            "Example:\n",
            "    search_facebook_users(\"Alex Chan\", limit=5)\n",
            "    â†’ [{\"id\": 123, \"display_name\": \"Alex Chan\", \"city\": \"Hong Kong\", \"country\": \"Hong Kong\", \"match_type\": \"exact\"}]\n",
            "    \n",
            "    search_facebook_users(\"Alx Chn\", limit=5)  # Typo - uses fuzzy matching\n",
            "    â†’ [{\"id\": 123, \"display_name\": \"Alex Chan\", \"city\": \"Hong Kong\", \"country\": \"Hong Kong\", \"match_type\": \"fuzzy\"}]\n",
            "\n",
            "Use case:\n",
            "    First step in CV verification - find candidate's Facebook profile to cross-check\n",
            "    personal information, location, and social connections. Handles typos and variations.\n",
            "{'q': {'type': 'string'}, 'limit': {'default': 20, 'type': 'integer'}, 'fuzzy': {'default': True, 'type': 'boolean'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n",
            "get_facebook_profile\n",
            "Retrieve complete Facebook profile including personal info, bio, relationships, and activity.\n",
            "\n",
            "Args:\n",
            "    user_id: Facebook user ID obtained from search_facebook_users()\n",
            "\n",
            "Returns:\n",
            "    Dictionary containing:\n",
            "    - id (int): Facebook user ID\n",
            "    - display_name (str): Public display name (may be nickname)\n",
            "    - original_name (str): Original/legal name from LinkedIn\n",
            "    - city (str): Current city\n",
            "    - country (str): Current country\n",
            "    - hometown (str|None): City/region where user grew up\n",
            "    - bio (str): Personal biography/interests\n",
            "    - status (str|None): Relationship status (Single, Married, etc.)\n",
            "    - education (str|None): Highest education level\n",
            "    - current_job (str|None): Current job title\n",
            "    - current_company (str|None): Current employer\n",
            "    - interests (str): Comma-separated hobbies/interests\n",
            "    - friends (List[int]): List of friend user IDs\n",
            "    - posts (List[dict]): Recent posts with id and content\n",
            "    \n",
            "    Returns {\"error\": \"User not found\"} if user_id is invalid.\n",
            "\n",
            "Example:\n",
            "    get_facebook_profile(123)\n",
            "    â†’ {\n",
            "        \"id\": 123,\n",
            "        \"display_name\": \"Sam Chan\",\n",
            "        \"original_name\": \"Alex Chan\",\n",
            "        \"city\": \"Hong Kong\",\n",
            "        \"hometown\": \"Kowloon\",\n",
            "        \"bio\": \"Software professional | Photography enthusiast\",\n",
            "        \"status\": \"Married\",\n",
            "        \"current_job\": \"Senior Engineer\",\n",
            "        \"current_company\": \"Google\",\n",
            "        \"friends\": [124, 125, 126],\n",
            "        \"posts\": [{\"id\": 1, \"content\": \"Excited to announce...\"}]\n",
            "    }\n",
            "\n",
            "Use case:\n",
            "    Verify candidate's personal details, check for name discrepancies,\n",
            "    validate current employment, and assess social connections.\n",
            "{'user_id': {'type': 'integer'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n",
            "get_facebook_mutual_friends\n",
            "Find mutual friends between two Facebook users (useful for verifying social connections).\n",
            "\n",
            "Args:\n",
            "    user_id_1: First Facebook user ID\n",
            "    user_id_2: Second Facebook user ID\n",
            "\n",
            "Returns:\n",
            "    Dictionary containing:\n",
            "    - user_1_id (int): First user's ID\n",
            "    - user_2_id (int): Second user's ID\n",
            "    - mutual_friends (List[int]): List of shared friend IDs\n",
            "    - mutual_count (int): Number of mutual friends\n",
            "    \n",
            "    Returns {\"error\": \"...\"} if either user not found.\n",
            "\n",
            "Example:\n",
            "    get_facebook_mutual_friends(123, 456)\n",
            "    â†’ {\"user_1_id\": 123, \"user_2_id\": 456, \"mutual_friends\": [789, 790], \"mutual_count\": 2}\n",
            "\n",
            "Use case:\n",
            "    Verify professional or personal relationships claimed in CV/references.\n",
            "{'user_id_1': {'type': 'integer'}, 'user_id_2': {'type': 'integer'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n",
            "search_linkedin_people\n",
            "Search LinkedIn profiles by name, headline, skills, or keywords with optional filters.\n",
            "\n",
            "Args:\n",
            "    q: Search query (matches name, headline, summary, or skill names)\n",
            "       Examples: \"software engineer\", \"Python\", \"data scientist\", \"Alex Chan\"\n",
            "    location: Filter by location (optional, case-insensitive, matches city OR country)\n",
            "              Examples: \"Hong Kong\", \"Singapore\", \"China\", \"USA\", \"New York\"\n",
            "    industry: Filter by industry (optional, case-insensitive)\n",
            "              Examples: \"Software\", \"Finance\", \"AI\", \"Consulting\"\n",
            "    limit: Maximum results to return (default: 20, max: 20)\n",
            "    fuzzy: Enable fuzzy matching if exact search returns no results (default: True)\n",
            "\n",
            "Returns:\n",
            "    List of profile dictionaries, each containing:\n",
            "    - id (int): LinkedIn profile ID for use with get_linkedin_profile()\n",
            "    - name (str): Full name\n",
            "    - headline (str): Professional headline/title\n",
            "    - industry (str): Industry sector\n",
            "    - location (str): \"City, Country\" format\n",
            "    - years_experience (int): Total years of work experience\n",
            "    - match_type (str): \"exact\" or \"fuzzy\"\n",
            "    \n",
            "    Returns empty list [] if no matches found.\n",
            "\n",
            "Example:\n",
            "    search_linkedin_people(\"Python developer\", location=\"Hong Kong\", limit=5)\n",
            "    â†’ [{\"id\": 456, \"name\": \"Alex Chan\", \"headline\": \"Senior Python Developer\", \n",
            "        \"industry\": \"Software\", \"location\": \"Hong Kong, Hong Kong\", \"years_experience\": 8, \"match_type\": \"exact\"}]\n",
            "    \n",
            "    search_linkedin_people(\"Pythn develper\", location=\"Hong Kong\", limit=5)  # Typo\n",
            "    â†’ [{\"id\": 456, \"name\": \"Alex Chan\", \"headline\": \"Senior Python Developer\", \n",
            "        \"industry\": \"Software\", \"location\": \"Hong Kong, Hong Kong\", \"years_experience\": 8, \"match_type\": \"fuzzy\"}]\n",
            "\n",
            "Use case:\n",
            "    Find candidate's LinkedIn profile using name, skills, or job title from CV.\n",
            "    Use location filter to narrow down results when common names exist. Handles typos.\n",
            "{'q': {'type': 'string'}, 'location': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None}, 'industry': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'default': None}, 'limit': {'default': 20, 'type': 'integer'}, 'fuzzy': {'default': True, 'type': 'boolean'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n",
            "get_linkedin_profile\n",
            "Retrieve complete LinkedIn professional profile including work history, education, and skills.\n",
            "\n",
            "Args:\n",
            "    person_id: LinkedIn profile ID obtained from search_linkedin_people()\n",
            "\n",
            "Returns:\n",
            "    Dictionary containing:\n",
            "    - id (int): LinkedIn profile ID\n",
            "    - name (str): Full name\n",
            "    - headline (str): Professional headline\n",
            "    - city (str): Current city\n",
            "    - country (str): Current country\n",
            "    - industry (str): Primary industry\n",
            "    - status (str): Employment status (employed, open_to_work, hiring, student)\n",
            "    - years_experience (int): Total years of professional experience\n",
            "    - summary (str): Professional summary/bio\n",
            "    \n",
            "    - skills (List[dict]): Each containing:\n",
            "        * name (str): Skill name (e.g., \"Python\", \"Machine Learning\")\n",
            "        * proficiency (int): Skill level 1-5 (1=beginner, 5=expert)\n",
            "    \n",
            "    - experience (List[dict]): Work history, each containing:\n",
            "        * company (str): Employer name\n",
            "        * title (str): Job title\n",
            "        * seniority (str): Level (junior, mid, senior)\n",
            "        * start_year (int): Employment start year\n",
            "        * end_year (int|None): Employment end year (None if current)\n",
            "        * is_current (bool): Whether currently employed here\n",
            "    \n",
            "    - education (List[dict]): Academic history, each containing:\n",
            "        * school (str): Institution name\n",
            "        * degree (str): Degree type (BSc, MSc, MBA, PhD)\n",
            "        * field (str): Field of study\n",
            "        * start_year (int): Start year\n",
            "        * end_year (int): Graduation year\n",
            "    \n",
            "    Returns {\"error\": \"Profile not found\"} if person_id is invalid.\n",
            "\n",
            "Example:\n",
            "    get_linkedin_profile(456)\n",
            "    â†’ {\n",
            "        \"id\": 456,\n",
            "        \"name\": \"Alex Chan\",\n",
            "        \"headline\": \"Senior Software Engineer\",\n",
            "        \"years_experience\": 8,\n",
            "        \"skills\": [\n",
            "            {\"name\": \"Python\", \"proficiency\": 5},\n",
            "            {\"name\": \"Docker\", \"proficiency\": 4}\n",
            "        ],\n",
            "        \"experience\": [\n",
            "            {\n",
            "                \"company\": \"Google\",\n",
            "                \"title\": \"Senior Engineer\",\n",
            "                \"seniority\": \"senior\",\n",
            "                \"start_year\": 2020,\n",
            "                \"end_year\": None,\n",
            "                \"is_current\": True\n",
            "            }\n",
            "        ],\n",
            "        \"education\": [\n",
            "            {\n",
            "                \"school\": \"HKUST\",\n",
            "                \"degree\": \"BSc\",\n",
            "                \"field\": \"Computer Science\",\n",
            "                \"start_year\": 2010,\n",
            "                \"end_year\": 2014\n",
            "            }\n",
            "        ]\n",
            "    }\n",
            "\n",
            "Use case:\n",
            "    Primary tool for CV verification - compare claimed experience, education,\n",
            "    skills, and employment dates against LinkedIn ground truth.\n",
            "{'person_id': {'type': 'integer'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n",
            "get_linkedin_interactions\n",
            "Retrieve LinkedIn engagement data showing who has interacted with a person's content.\n",
            "\n",
            "Args:\n",
            "    person_id: LinkedIn profile ID\n",
            "\n",
            "Returns:\n",
            "    Dictionary containing:\n",
            "    - profile_id (int): The person's LinkedIn ID\n",
            "    - post_count (int): Number of posts made\n",
            "    - total_likes (int): Total likes received across all posts\n",
            "    - liked_by (List[int]): Unique profile IDs who have liked this person's posts\n",
            "    - engagement_score (float): Likes per post ratio\n",
            "    \n",
            "    Returns {\"profile_id\": X, \"liked_by\": [], ...} if person has no posts.\n",
            "\n",
            "Example:\n",
            "    get_linkedin_interactions(456)\n",
            "    â†’ {\n",
            "        \"profile_id\": 456,\n",
            "        \"post_count\": 10,\n",
            "        \"total_likes\": 150,\n",
            "        \"liked_by\": [123, 124, 125],\n",
            "        \"engagement_score\": 15.0\n",
            "    }\n",
            "\n",
            "Use case:\n",
            "    Assess professional network strength and content engagement.\n",
            "    Verify connections to claimed colleagues or industry peers.\n",
            "{'person_id': {'type': 'integer'}}\n",
            "\n",
            "\n",
            "------------------------------------------------------\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A simple agent using tools from the MCP server\n"
      ],
      "metadata": {
        "id": "ABoe2-qfXl7r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
        "\n",
        "# ---------------------------\n",
        "# 1. Define a local tool\n",
        "# ---------------------------\n",
        "@tool\n",
        "def say_hello(name: str) -> str:\n",
        "    \"\"\"Say hello to a person by name.\"\"\"\n",
        "    return f\"Hello, {name}! ğŸ‘‹\"\n",
        "\n",
        "# ---------------------------\n",
        "# 2. Load MCP tools + merge\n",
        "# ---------------------------\n",
        "client = MultiServerMCPClient({\n",
        "    \"social_graph\": {\n",
        "        \"transport\": \"http\",\n",
        "        \"url\": \"https://ftec5660.ngrok.app/mcp\",\n",
        "        \"headers\": {\"ngrok-skip-browser-warning\": \"true\"}\n",
        "    }\n",
        "})\n",
        "\n",
        "mcp_tools = await client.get_tools()\n",
        "tools = mcp_tools + [say_hello]\n",
        "\n",
        "# ---------------------------\n",
        "# 3. Initialize Gemini (tool-enabled) or deepseek\n",
        "# ---------------------------\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import google.auth\n",
        "credentials, _ = google.auth.default()\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    vertexai=True,\n",
        "    project=\"my-project-5760-485607\",\n",
        "    location=\"us-central1\",\n",
        "    credentials=credentials,\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "# ---------------------------\n",
        "# 4. Single-step invocation\n",
        "# ---------------------------\n",
        "query = \"Say hello to Bao using tool, then search for someone named Alice on Facebook.\"\n",
        "\n",
        "response = llm_with_tools.invoke([\n",
        "    HumanMessage(content=query)\n",
        "])\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtTjwFKhTKn3",
        "outputId": "91d9b456-564c-4f79-a934-0df8fdf36c9a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='' additional_kwargs={'function_call': {'name': 'search_facebook_users', 'arguments': '{\"q\": \"Alice\"}'}, '__gemini_function_call_thought_signatures__': {'b4e7759c-c4d0-4d1e-aad0-2e2b24d43ef7': 'CtkDAY89a19ySfb9GkymoRFnAzJPjJsBOpx1wkTF6Tjtn2vjjGmHqB29PCCVFdbBKYJCV+CoFHgR3Bxs0oU4+lXMOyWzJEO67g4l+V356PNrTW9v1d8HUhazcwX6vv35heB82q86qP84Un578wSM8i0d3AZ75bNrpBBJZo/BW3BQfevZeYmS6vTxMbZ7Ghu6/BbX3BL9BYKttvzc+JCGik81TrLjISIb8Gw8Tss0wm/3dWFVbBHR67cXcpwqDKo/El7LLhFWvJ0JCVkY38vUIAm0GVDbVlmxFv1ITIqcLmPDOaeHh51TucRUyiFN49LnxCgR1ICyeg62hYBJc1SM/J3YuUUSj+Gx1kr9nuIVzerXsClBpHk84W23iFnaCML6+Z/15o3o684b64Nlqa+J/drjl0RBI5ajV08lpekgh6jRQZH7lWCdls90TM8FoJoUlkho52uPP/bXdu73L1AQ05eSQmlrJb5d2ZEpsQcU3Bt4iuMFXf8tlHbKXNO3uMJVx+rfPv3i9UpQmIWEvQL4ohUwQeeW1wmXkKO4gLQsQQnGKa3irf00+ZhDXep2YrBxD//5y/CDfvkPp3atvCvTGLy8k8QdjkSGkx/oOGm5FD89tcgYl7ekXpGoUjc='}} response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'} id='lc_run--019c9e2c-16c9-7230-8f70-793d49123d0c-0' tool_calls=[{'name': 'say_hello', 'args': {'name': 'Bao'}, 'id': 'b4e7759c-c4d0-4d1e-aad0-2e2b24d43ef7', 'type': 'tool_call'}, {'name': 'search_facebook_users', 'args': {'q': 'Alice'}, 'id': 'faf66be6-ea16-4eb5-adf7-35f94ab0952e', 'type': 'tool_call'}] invalid_tool_calls=[] usage_metadata={'input_tokens': 2568, 'output_tokens': 124, 'total_tokens': 2692, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 111}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This block provides you some tests to get faminilar with our MCP server\n",
        "\n",
        "# # Test 1: Search Facebook users (exact match)\n",
        "# await tools[0].ainvoke({'q': \"Alex Chan\", 'limit': 5})\n",
        "\n",
        "# # Test 2: Search Facebook users (fuzzy match with typo)\n",
        "# await tools[0].ainvoke({'q': \"Alx Chn\", 'limit': 5, 'fuzzy': True})\n",
        "\n",
        "# # Test 3: Get Facebook profile\n",
        "# await tools[1].ainvoke({'user_id': 123})\n",
        "\n",
        "# # Test 4: Get Facebook mutual friends\n",
        "# await tools[2].ainvoke({'user_id_1': 123, 'user_id_2': 456})\n",
        "\n",
        "# # Test 5: Search LinkedIn people (exact match)\n",
        "# await tools[3].ainvoke({'q': \"Python\", 'location': \"Hong Kong\", 'limit': 5})\n",
        "\n",
        "# # Test 6: Search LinkedIn people (fuzzy match with typo)\n",
        "# await tools[3].ainvoke({'q': \"Python\", 'location': \"Hong Kong\", 'limit': 5, 'fuzzy': True})\n",
        "\n",
        "# # Test 7: Get LinkedIn profile\n",
        "# await tools[4].ainvoke({'person_id': 456})\n",
        "\n",
        "# Test 8: Get LinkedIn interactions\n",
        "await tools[5].ainvoke({'person_id': 456})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhLeoXGrqesW",
        "outputId": "6d9878c3-9d94-447f-ddfa-d2c52b5b0bf6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'type': 'text',\n",
              "  'text': '{\"profile_id\":456,\"post_count\":4,\"total_likes\":5,\"liked_by\":[4390,3622,7500,4269,8464],\"engagement_score\":1.25}',\n",
              "  'id': 'lc_b2e31d3d-16b6-48c3-9959-1f1039fbadf3'}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Homework2 Code"
      ],
      "metadata": {
        "id": "p0G-yfpyOFcx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "# Complete CV Verification Agent System for Homework 2\n",
        "# With DETAILED PROCESS VISUALIZATION + HUMAN-LIKE SCORING\n",
        "# =====================================================\n",
        "\n",
        "import asyncio\n",
        "import json\n",
        "import re\n",
        "from datetime import datetime\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import google.auth\n",
        "credentials, _ = google.auth.default()\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "# -------------------------\n",
        "# Initialize Gemini\n",
        "# -------------------------\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    vertexai=True,\n",
        "    project=\"my-project-5760-485607\",\n",
        "    location=\"global\",\n",
        "    credentials=credentials,\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# Connect MCP Server\n",
        "# -------------------------\n",
        "client = MultiServerMCPClient({\n",
        "    \"social_graph\": {\n",
        "        \"transport\": \"http\",\n",
        "        \"url\": \"https://ftec5660.ngrok.app/mcp\",\n",
        "        \"headers\": {\"ngrok-skip-browser-warning\": \"true\"}\n",
        "    }\n",
        "})\n",
        "\n",
        "mcp_tools = await client.get_tools()\n",
        "tools_dict = {tool.name: tool for tool in mcp_tools}\n",
        "print(f\"âœ… Connected to MCP Server. Available tools: {list(tools_dict.keys())}\")\n",
        "\n",
        "# =====================================================\n",
        "# 1. Extract Structured Information from CV\n",
        "# =====================================================\n",
        "def extract_cv_structure(cv_text: str) -> dict:\n",
        "    \"\"\"Extract structured information from CV text using LLM\"\"\"\n",
        "    print(f\"\\n  ğŸ“„ [Step 1] Parsing CV text...\")\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are an expert CV parser. Extract structured information from the CV below.\n",
        "\n",
        "Return ONLY valid JSON with this exact format:\n",
        "{{\n",
        "  \"full_name\": \"\",\n",
        "  \"location\": \"\",\n",
        "  \"education\": [\n",
        "    {{\n",
        "      \"degree\": \"\",\n",
        "      \"institution\": \"\",\n",
        "      \"year\": \"\"\n",
        "    }}\n",
        "  ],\n",
        "  \"work_experience\": [\n",
        "    {{\n",
        "      \"title\": \"\",\n",
        "      \"company\": \"\",\n",
        "      \"start_year\": \"\",\n",
        "      \"end_year\": \"\"\n",
        "    }}\n",
        "  ],\n",
        "  \"skills\": []\n",
        "}}\n",
        "\n",
        "CV TEXT:\n",
        "{cv_text}\n",
        "\"\"\"\n",
        "\n",
        "    response = llm.invoke([HumanMessage(content=prompt)])\n",
        "    raw_output = response.content.strip()\n",
        "    raw_output = re.sub(r\"```json|```\", \"\", raw_output).strip()\n",
        "\n",
        "    try:\n",
        "        result = json.loads(raw_output)\n",
        "        print(f\"    âœ… Extracted: {result.get('full_name', 'Unknown')} - {len(result.get('work_experience', []))} jobs, {len(result.get('education', []))} degrees\")\n",
        "        return result\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"    âŒ JSON parsing failed\")\n",
        "        return {}\n",
        "\n",
        "# =====================================================\n",
        "# 2. LinkedIn Search Functions\n",
        "# =====================================================\n",
        "async def search_linkedin_profiles(name: str, location: str = None, limit: int = 5):\n",
        "    \"\"\"Search LinkedIn profiles by name\"\"\"\n",
        "    search_tool = tools_dict.get(\"search_linkedin_people\")\n",
        "    if not search_tool:\n",
        "        return []\n",
        "\n",
        "    params = {'q': name, 'limit': limit, 'fuzzy': True}\n",
        "    if location:\n",
        "        params['location'] = location\n",
        "\n",
        "    try:\n",
        "        response = await search_tool.ainvoke(params)\n",
        "        if isinstance(response, list):\n",
        "            for item in response:\n",
        "                if isinstance(item, dict) and 'text' in item:\n",
        "                    try:\n",
        "                        data = json.loads(item['text'])\n",
        "                        if isinstance(data, list):\n",
        "                            return data\n",
        "                    except:\n",
        "                        continue\n",
        "    except Exception as e:\n",
        "        print(f\"      Search error: {e}\")\n",
        "    return []\n",
        "\n",
        "async def get_linkedin_profile(person_id: int):\n",
        "    \"\"\"Get complete LinkedIn profile by ID\"\"\"\n",
        "    profile_tool = tools_dict.get(\"get_linkedin_profile\")\n",
        "    if not profile_tool:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        response = await profile_tool.ainvoke({'person_id': person_id})\n",
        "        if isinstance(response, list):\n",
        "            for item in response:\n",
        "                if isinstance(item, dict) and 'text' in item:\n",
        "                    try:\n",
        "                        data = json.loads(item['text'])\n",
        "                        if isinstance(data, dict) and 'error' not in data:\n",
        "                            return data\n",
        "                    except:\n",
        "                        continue\n",
        "    except:\n",
        "        pass\n",
        "    return None\n",
        "\n",
        "# =====================================================\n",
        "# 3. Find Best Matching Profile with Detailed Visualization\n",
        "# =====================================================\n",
        "async def find_best_matching_profile(name: str, cv_data: dict) -> dict:\n",
        "    \"\"\"Find the best LinkedIn profile with detailed visualization\"\"\"\n",
        "\n",
        "    print(f\"\\n  ğŸ” [Step 2] Searching LinkedIn for {name}...\")\n",
        "\n",
        "    # Extract context from CV\n",
        "    cv_companies = [exp.get('company', '').lower() for exp in cv_data.get('work_experience', []) if exp.get('company')]\n",
        "    cv_schools = [edu.get('institution', '').lower() for edu in cv_data.get('education', []) if edu.get('institution')]\n",
        "    cv_location = cv_data.get('location', '').lower()\n",
        "\n",
        "    print(f\"\\n    ğŸ“‹ CV Context Analysis:\")\n",
        "    print(f\"      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
        "    print(f\"      â”‚ Companies: {cv_companies}\")\n",
        "    print(f\"      â”‚ Schools:   {cv_schools}\")\n",
        "    print(f\"      â”‚ Location:  {cv_location}\")\n",
        "    print(f\"      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\")\n",
        "\n",
        "\n",
        "    print(f\"\\n    ğŸ” Searching with name\")\n",
        "    profiles = await search_linkedin_profiles(name, limit=30)\n",
        "    print(f\"      â†’ Found {len(profiles)} profiles\")\n",
        "\n",
        "    if not profiles:\n",
        "        print(f\"      âŒ No profiles found\")\n",
        "        return None\n",
        "\n",
        "    print(f\"\\n    ğŸ“Š Evaluating top {min(5, len(profiles))} profiles...\")\n",
        "    print(f\"      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
        "\n",
        "    # Get full profiles for top candidates and calculate match scores\n",
        "    candidates = []\n",
        "    for idx, profile in enumerate(profiles[:5]):  # Check top 5\n",
        "        print(f\"      â”‚ [{idx+1}/5] Checking {profile.get('name', 'Unknown'):20} - {profile.get('headline', 'N/A')[:40]:40}\")\n",
        "        full = await get_linkedin_profile(profile['id'])\n",
        "\n",
        "        if full:\n",
        "            # Detailed match analysis\n",
        "            match_details = {\n",
        "                'company_matches': [],\n",
        "                'school_matches': [],\n",
        "                'location_match': False,\n",
        "                'industry_match': False\n",
        "            }\n",
        "\n",
        "            # Check company matches\n",
        "            profile_companies = [exp.get('company', '').lower() for exp in full.get('experience', [])]\n",
        "            for cv_company in cv_companies:\n",
        "                for pc in profile_companies:\n",
        "                    if cv_company in pc or pc in cv_company:\n",
        "                        match_details['company_matches'].append(cv_company)\n",
        "                        print(f\"      â”‚   âœ“ Company: '{cv_company}' matches LinkedIn\")\n",
        "\n",
        "            # Check school matches\n",
        "            profile_schools = [edu.get('school', '').lower() for edu in full.get('education', [])]\n",
        "            for cv_school in cv_schools:\n",
        "                for ps in profile_schools:\n",
        "                    if cv_school in ps or ps in cv_school:\n",
        "                        match_details['school_matches'].append(cv_school)\n",
        "                        print(f\"      â”‚   âœ“ School:  '{cv_school}' matches LinkedIn\")\n",
        "\n",
        "            # Check location match\n",
        "            profile_city = full.get('city', '').lower()\n",
        "            profile_country = full.get('country', '').lower()\n",
        "            if cv_location and (cv_location in profile_city or cv_location in profile_country):\n",
        "                match_details['location_match'] = True\n",
        "                print(f\"      â”‚   âœ“ Location: '{cv_location}' matches '{profile_city}, {profile_country}'\")\n",
        "\n",
        "            # Calculate match score\n",
        "            match_score = (len(match_details['company_matches']) * 3 +\n",
        "                          len(match_details['school_matches']) * 2 +\n",
        "                          (1 if match_details['location_match'] else 0))\n",
        "\n",
        "            print(f\"      â”‚   ğŸ“Š Match Score: {match_score} (C:{len(match_details['company_matches'])*3} + S:{len(match_details['school_matches'])*2} + L:{1 if match_details['location_match'] else 0})\")\n",
        "\n",
        "            candidates.append({\n",
        "                'profile': profile,\n",
        "                'full': full,\n",
        "                'match_score': match_score,\n",
        "                'match_details': match_details\n",
        "            })\n",
        "        else:\n",
        "            print(f\"      â”‚   âŒ Could not retrieve full profile\")\n",
        "\n",
        "    print(f\"      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\")\n",
        "\n",
        "    if not candidates:\n",
        "        print(f\"\\n      âŒ Could not retrieve any full profiles\")\n",
        "        return None\n",
        "\n",
        "    # Sort by match score\n",
        "    candidates.sort(key=lambda x: x['match_score'], reverse=True)\n",
        "    best = candidates[0]\n",
        "\n",
        "    print(f\"\\n    ğŸ† Best Match Selected:\")\n",
        "    print(f\"      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
        "    print(f\"      â”‚ Name:     {best['profile'].get('name')}\")\n",
        "    print(f\"      â”‚ Headline: {best['profile'].get('headline')}\")\n",
        "    print(f\"      â”‚ Match Score: {best['match_score']}/10\")\n",
        "    print(f\"      â”‚ Company Matches: {best['match_details']['company_matches']}\")\n",
        "    print(f\"      â”‚ School Matches:  {best['match_details']['school_matches']}\")\n",
        "    print(f\"      â”‚ Location Match:  {best['match_details']['location_match']}\")\n",
        "    print(f\"      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\")\n",
        "\n",
        "    if best['match_score'] >= 4:\n",
        "        verdict = \"âœ… Strong match - highly likely the same person\"\n",
        "    elif best['match_score'] >= 2:\n",
        "        verdict = \"âš ï¸ Partial match - possibly the same person\"\n",
        "    else:\n",
        "        verdict = \"âŒ Weak match - likely different person with same name\"\n",
        "    print(f\"      Verdict: {verdict}\")\n",
        "\n",
        "    return {\n",
        "        'search_match': best['profile'],\n",
        "        'full_profile': best['full'],\n",
        "        'match_score': best['match_score'],\n",
        "        'match_details': best['match_details']\n",
        "    }\n",
        "\n",
        "# ===================================\n",
        "# 4. Human-Like LLM Scoring\n",
        "# ===================================\n",
        "def human_like_scoring(cv_data: dict, linkedin_data: dict, match_info: dict) -> dict:\n",
        "    \"\"\"Use LLM to score like a human - avoids 0.5 as default\"\"\"\n",
        "\n",
        "    print(f\"\\n  ğŸ§  [Step 3] LLM Human-Like Analysis...\")\n",
        "    print(f\"    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\")\n",
        "    print(f\"    â”‚ Starting detailed comparison...                                â”‚\")\n",
        "    print(f\"    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\")\n",
        "\n",
        "    if not linkedin_data or not linkedin_data.get('full_profile'):\n",
        "        print(f\"\\n    âŒ No LinkedIn profile available\")\n",
        "        return {\n",
        "            \"consistency_score\": 0.1,  # Very low for no profile\n",
        "            \"education_analysis\": \"No LinkedIn profile found for verification\",\n",
        "            \"work_experience_analysis\": \"No LinkedIn profile found for verification\",\n",
        "            \"location_analysis\": \"No LinkedIn profile found for verification\",\n",
        "            \"discrepancies\": [\"No social media profile available\"],\n",
        "            \"llm_reasoning\": \"No LinkedIn profile to analyze\",\n",
        "            \"overall_reasoning\": \"CV cannot be verified due to missing LinkedIn profile\",\n",
        "            \"verification_status\": \"unverified\"\n",
        "        }\n",
        "\n",
        "    full_profile = linkedin_data['full_profile']\n",
        "    match_score = match_info.get('match_score', 0)\n",
        "    match_details = match_info.get('match_details', {})\n",
        "\n",
        "    # If match score is very low, this is probably the wrong person\n",
        "    if match_score < 2 and len(match_details.get('company_matches', [])) == 0 and len(match_details.get('school_matches', [])) == 0:\n",
        "        print(f\"\\n    âš ï¸ Match score too low ({match_score}) - likely wrong person\")\n",
        "        return {\n",
        "            \"consistency_score\": 0.0,  # Very low for wrong person\n",
        "            \"education_analysis\": f\"Found LinkedIn profile for {full_profile.get('name', 'Unknown')} but no matching companies/schools\",\n",
        "            \"work_experience_analysis\": f\"CV companies: {[c for c in cv_data.get('work_experience', [])]}, LinkedIn shows: {[exp.get('company') for exp in full_profile.get('experience', [])[:3]]}\",\n",
        "            \"location_analysis\": f\"CV location: {cv_data.get('location', 'N/A')}, LinkedIn: {full_profile.get('city', 'N/A')}, {full_profile.get('country', 'N/A')}\",\n",
        "            \"discrepancies\": [\"Profile may belong to different person with same name\"],\n",
        "            \"llm_reasoning\": f\"Match score {match_score} indicates this is likely a different person with the same name\",\n",
        "            \"overall_reasoning\": \"The LinkedIn profile found has the same name but completely different work history - likely a different person\",\n",
        "            \"verification_status\": \"wrong_person\"\n",
        "        }\n",
        "\n",
        "    # Detailed LLM analysis with human-like scoring\n",
        "    prompt = f\"\"\"\n",
        "You are a human CV verification expert. You need to compare a CV with a LinkedIn profile and assign a score based on how a real human would judge.\n",
        "\n",
        "CRITICAL SCORING RULES (NO 0.5 DEFAULT):\n",
        "- 0.95-1.00: Perfect match - all key information matches exactly\n",
        "- 0.85-0.94: Excellent match - minor, insignificant differences only\n",
        "- 0.70-0.84: Good match - some small discrepancies but core info matches\n",
        "- 0.60-0.69: Fair match - noticeable discrepancies but still probably same person\n",
        "- 0.40-0.59: Mixed match - significant discrepancies, unsure if same person\n",
        "- 0.20-0.39: Poor match - major discrepancies, likely different person\n",
        "- 0.00-0.19: Complete mismatch - definitely different person\n",
        "\n",
        "DATA TO COMPARE:\n",
        "\n",
        "CV DATA:\n",
        "{json.dumps(cv_data, indent=2, ensure_ascii=False)}\n",
        "\n",
        "LINKEDIN PROFILE:\n",
        "{json.dumps(full_profile, indent=2, ensure_ascii=False)}\n",
        "\n",
        "MATCH INDICATORS:\n",
        "- Match Score: {match_score}/10\n",
        "- Matching Companies: {match_details.get('company_matches', [])}\n",
        "- Matching Schools: {match_details.get('school_matches', [])}\n",
        "- Location Match: {match_details.get('location_match', False)}\n",
        "\n",
        "Now, think step by step like a human:\n",
        "\n",
        "STEP 1 - Education Comparison:\n",
        "CV Education: {json.dumps(cv_data.get('education', []), indent=2)}\n",
        "LinkedIn Education: {json.dumps(full_profile.get('education', []), indent=2)}\n",
        "â†’ Do the institutions match? Degrees? Years?\n",
        "â†’ Rate education consistency: (perfect/good/fair/poor)\n",
        "\n",
        "STEP 2 - Work Experience Comparison:\n",
        "CV Experience: {json.dumps(cv_data.get('work_experience', []), indent=2)}\n",
        "LinkedIn Experience: {json.dumps(full_profile.get('experience', []), indent=2)}\n",
        "â†’ Do the companies match? Job titles? Dates?\n",
        "â†’ Rate work consistency: (perfect/good/fair/poor)\n",
        "\n",
        "STEP 3 - Location & Industry:\n",
        "CV Location: {cv_data.get('location', 'N/A')}\n",
        "LinkedIn Location: {full_profile.get('city', 'N/A')}, {full_profile.get('country', 'N/A')}\n",
        "LinkedIn Industry: {full_profile.get('industry', 'N/A')}\n",
        "â†’ Rate location consistency: (perfect/good/fair/poor)\n",
        "\n",
        "STEP 4 - Overall Human Judgment:\n",
        "Based on all the above, what would a human recruiter think?\n",
        "- Is this clearly the same person?\n",
        "- Is this clearly a different person?\n",
        "- Or is it ambiguous?\n",
        "\n",
        "Return your analysis in this JSON format:\n",
        "{{\n",
        "  \"consistency_score\": 0.0,\n",
        "  \"education_analysis\": \"Detailed education comparison with reasoning\",\n",
        "  \"work_experience_analysis\": \"Detailed work experience comparison with reasoning\",\n",
        "  \"location_analysis\": \"Location comparison with reasoning\",\n",
        "  \"discrepancies\": [\"List\", \"of\", \"specific\", \"discrepancies\", \"found\"],\n",
        "  \"matches\": [\"List\", \"of\", \"things\", \"that\", \"match\"],\n",
        "  \"llm_reasoning\": \"Your step-by-step reasoning process as a human expert\",\n",
        "  \"human_verdict\": \"clearly_same_person/probably_same_person/ambiguous/probably_different/clearly_different\",\n",
        "  \"overall_reasoning\": \"Final summary of your judgment\"\n",
        "}}\n",
        "\n",
        "Remember: Be specific about what matches and what doesn't. Avoid 0.5 as a default.\n",
        "\"\"\"\n",
        "\n",
        "    print(f\"\\n    ğŸ’­ LLM is now thinking like a human...\")\n",
        "    response = llm.invoke([HumanMessage(content=prompt)])\n",
        "\n",
        "    try:\n",
        "        content = response.content.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
        "        result = json.loads(content)\n",
        "\n",
        "        # Print the LLM's reasoning process\n",
        "        print(f\"\\n    ğŸ“ LLM Reasoning Process:\")\n",
        "        reasoning = result.get('llm_reasoning', 'No reasoning provided')\n",
        "        for line in reasoning.split('\\n'):\n",
        "            if line.strip():\n",
        "                print(f\"      {line}\")\n",
        "\n",
        "        print(f\"\\n    ğŸ“Š Final Score: {result.get('consistency_score', 0.0):.2f}\")\n",
        "        print(f\"    ğŸ·ï¸  Human Verdict: {result.get('human_verdict', 'unknown')}\")\n",
        "\n",
        "        # Print matches\n",
        "        matches = result.get('matches', [])\n",
        "        if matches:\n",
        "            print(f\"\\n    âœ… What matches:\")\n",
        "            for m in matches:\n",
        "                print(f\"      â€¢ {m}\")\n",
        "\n",
        "        # Print discrepancies\n",
        "        discrepancies = result.get('discrepancies', [])\n",
        "        if discrepancies:\n",
        "            print(f\"\\n    âŒ What doesn't match:\")\n",
        "            for d in discrepancies:\n",
        "                print(f\"      â€¢ {d}\")\n",
        "\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        print(f\"\\n    âš ï¸ Error parsing LLM response: {e}\")\n",
        "        # Fallback based on match score - but avoid 0.5\n",
        "        if match_score >= 5:\n",
        "            fallback = 0.85\n",
        "            verdict = \"probably_same_person\"\n",
        "        elif match_score >= 3:\n",
        "            fallback = 0.65\n",
        "            verdict = \"ambiguous\"\n",
        "        elif match_score >= 1:\n",
        "            fallback = 0.30\n",
        "            verdict = \"probably_different\"\n",
        "        else:\n",
        "            fallback = 0.10\n",
        "            verdict = \"clearly_different\"\n",
        "\n",
        "        return {\n",
        "            \"consistency_score\": fallback,\n",
        "            \"education_analysis\": f\"Based on match quality (score: {match_score})\",\n",
        "            \"work_experience_analysis\": f\"Company matches: {match_details.get('company_matches', [])}\",\n",
        "            \"location_analysis\": f\"Location match: {match_details.get('location_match', False)}\",\n",
        "            \"discrepancies\": [\"Used fallback scoring\"],\n",
        "            \"matches\": match_details.get('company_matches', []) + match_details.get('school_matches', []),\n",
        "            \"llm_reasoning\": f\"LLM response parsing failed. Using match score {match_score} as fallback.\",\n",
        "            \"human_verdict\": verdict,\n",
        "            \"overall_reasoning\": f\"Based on matching companies/schools: {match_details}\"\n",
        "        }\n",
        "\n",
        "# =====================================================\n",
        "# 5. Main Verification Function with Full Process Display\n",
        "# =====================================================\n",
        "async def verify_single_cv(cv_entry: dict, index: int) -> dict:\n",
        "    \"\"\"Process a single CV with full process visualization\"\"\"\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"ğŸ“ CV {index+1}: {cv_entry['file']}\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    # Step 1: Extract CV info\n",
        "    cv_data = extract_cv_structure(cv_entry[\"text\"])\n",
        "    if not cv_data:\n",
        "        return {\n",
        "            \"file\": cv_entry[\"file\"],\n",
        "            \"name\": \"Unknown\",\n",
        "            \"score\": 0.0,\n",
        "            \"analysis\": {\n",
        "                \"consistency_score\": 0.0,\n",
        "                \"llm_reasoning\": \"Failed to parse CV\",\n",
        "                \"human_verdict\": \"error\",\n",
        "                \"overall_reasoning\": \"Could not extract structured data from CV\"\n",
        "            }\n",
        "        }\n",
        "\n",
        "    name = cv_data.get(\"full_name\", \"\")\n",
        "\n",
        "    # Step 2: Find best matching profile\n",
        "    linkedin_result = await find_best_matching_profile(name, cv_data)\n",
        "\n",
        "    # Step 3: Human-like scoring\n",
        "    if not linkedin_result:\n",
        "        analysis = {\n",
        "            \"consistency_score\": 0.1,\n",
        "            \"education_analysis\": \"No LinkedIn profile found\",\n",
        "            \"work_experience_analysis\": \"No LinkedIn profile found\",\n",
        "            \"location_analysis\": \"No LinkedIn profile found\",\n",
        "            \"discrepancies\": [\"No LinkedIn profile available\"],\n",
        "            \"matches\": [],\n",
        "            \"llm_reasoning\": \"Search returned no LinkedIn profiles\",\n",
        "            \"human_verdict\": \"unverifiable\",\n",
        "            \"overall_reasoning\": f\"No LinkedIn profile found for {name}\"\n",
        "        }\n",
        "        score = 0.1\n",
        "    else:\n",
        "        analysis = human_like_scoring(cv_data, linkedin_result, linkedin_result)\n",
        "        score = analysis.get(\"consistency_score\", 0.0)\n",
        "\n",
        "    print(f\"\\n    {'â”€'*50}\")\n",
        "    print(f\"    FINAL VERDICT: Score = {score:.2f} | {analysis.get('human_verdict', 'unknown')}\")\n",
        "    print(f\"    {'â”€'*50}\")\n",
        "\n",
        "    return {\n",
        "        \"file\": cv_entry[\"file\"],\n",
        "        \"name\": name,\n",
        "        \"score\": score,\n",
        "        \"analysis\": analysis\n",
        "    }\n",
        "\n",
        "# =====================================================\n",
        "# 6. Run Verification\n",
        "# =====================================================\n",
        "async def verify_all_cvs(cv_list):\n",
        "    \"\"\"Process all CVs and return results\"\"\"\n",
        "    results = []\n",
        "    for i, cv in enumerate(cv_list):\n",
        "        result = await verify_single_cv(cv, i)\n",
        "        results.append(result)\n",
        "    return results\n",
        "\n",
        "print(\"\\nğŸš€ Starting CV Verification System\")\n",
        "print(f\"ğŸ“Š Processing {len(all_cvs)} CVs...\\n\")\n",
        "\n",
        "results = await verify_all_cvs(all_cvs)\n",
        "\n",
        "# =====================================================\n",
        "# 7. Generate Detailed Report\n",
        "# =====================================================\n",
        "def generate_report(results):\n",
        "    \"\"\"Generate comprehensive report\"\"\"\n",
        "\n",
        "    report = []\n",
        "    report.append(\"# CV Verification System Report\")\n",
        "    report.append(\"\")\n",
        "    report.append(f\"**Date:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "    report.append(f\"**CVs Processed:** {len(results)}\")\n",
        "    report.append(\"\")\n",
        "\n",
        "    # Summary table\n",
        "    report.append(\"## 1. Summary of Results\")\n",
        "    report.append(\"\")\n",
        "    report.append(\"| CV File | Candidate | Score | Human Verdict |\")\n",
        "    report.append(\"|---------|-----------|-------|---------------|\")\n",
        "\n",
        "    scores = []\n",
        "    for r in results:\n",
        "        score = r['score']\n",
        "        scores.append(score)\n",
        "        verdict = r.get('analysis', {}).get('human_verdict', 'unknown')\n",
        "        report.append(f\"| {r['file']} | {r['name']} | {score:.2f} | {verdict} |\")\n",
        "\n",
        "    report.append(\"\")\n",
        "\n",
        "    # Detailed Analysis\n",
        "    report.append(\"## 2. Detailed Analysis with LLM Reasoning\")\n",
        "    report.append(\"\")\n",
        "\n",
        "    for i, r in enumerate(results):\n",
        "        report.append(f\"### CV {i+1}: {r['file']} - {r['name']}\")\n",
        "        report.append(\"\")\n",
        "        report.append(f\"**Final Score:** {r['score']:.2f}\")\n",
        "        report.append(f\"**Human Verdict:** {r.get('analysis', {}).get('human_verdict', 'unknown')}\")\n",
        "        report.append(\"\")\n",
        "\n",
        "        analysis = r.get('analysis', {})\n",
        "\n",
        "        # LLM Reasoning\n",
        "        report.append(\"**LLM Reasoning Process:**\")\n",
        "        report.append(\"```\")\n",
        "        report.append(analysis.get('llm_reasoning', 'No reasoning provided'))\n",
        "        report.append(\"```\")\n",
        "        report.append(\"\")\n",
        "\n",
        "        # Matches\n",
        "        matches = analysis.get('matches', [])\n",
        "        if matches:\n",
        "            report.append(\"**âœ… What Matches:**\")\n",
        "            for m in matches:\n",
        "                report.append(f\"- {m}\")\n",
        "            report.append(\"\")\n",
        "\n",
        "        # Discrepancies\n",
        "        discrepancies = analysis.get('discrepancies', [])\n",
        "        if discrepancies:\n",
        "            report.append(\"**âŒ Discrepancies Found:**\")\n",
        "            for d in discrepancies:\n",
        "                report.append(f\"- {d}\")\n",
        "            report.append(\"\")\n",
        "\n",
        "        # Detailed analyses\n",
        "        if analysis.get('education_analysis'):\n",
        "            report.append(\"**Education Analysis:**\")\n",
        "            report.append(analysis['education_analysis'])\n",
        "            report.append(\"\")\n",
        "\n",
        "        if analysis.get('work_experience_analysis'):\n",
        "            report.append(\"**Work Experience Analysis:**\")\n",
        "            report.append(analysis['work_experience_analysis'])\n",
        "            report.append(\"\")\n",
        "\n",
        "        if analysis.get('location_analysis'):\n",
        "            report.append(\"**Location Analysis:**\")\n",
        "            report.append(analysis['location_analysis'])\n",
        "            report.append(\"\")\n",
        "\n",
        "        report.append(\"**Overall Reasoning:**\")\n",
        "        report.append(analysis.get('overall_reasoning', 'N/A'))\n",
        "        report.append(\"\")\n",
        "        report.append(\"---\")\n",
        "        report.append(\"\")\n",
        "\n",
        "    return \"\\n\".join(report)\n",
        "\n",
        "# Generate report\n",
        "report_text = generate_report(results)\n",
        "with open(\"verification_report.md\", \"w\") as f:\n",
        "    f.write(report_text)\n",
        "print(\"\\nâœ… Detailed report saved to verification_report.md\")\n",
        "\n",
        "# =====================================================\n",
        "# 8. Evaluation\n",
        "# =====================================================\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ğŸ“Š EVALUATION RESULTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "groundtruth = [1, 1, 1, 0, 0]\n",
        "scores = [r['score'] for r in results]\n",
        "\n",
        "correct = 0\n",
        "for i, (score, truth) in enumerate(zip(scores, groundtruth)):\n",
        "    pred = 1 if score > 0.5 else 0\n",
        "    if pred == truth:\n",
        "        correct += 1\n",
        "        status = \"âœ“\"\n",
        "    else:\n",
        "        status = \"âœ—\"\n",
        "\n",
        "    verdict = results[i].get('analysis', {}).get('human_verdict', 'unknown')\n",
        "    print(f\"CV_{i+1}: {results[i]['file']}\")\n",
        "    print(f\"   Score: {score:.2f} | Pred: {pred} | Truth: {truth} {status}\")\n",
        "    print(f\"   Verdict: {verdict}\")\n",
        "    print()\n",
        "\n",
        "accuracy = correct / 5\n",
        "print(f\"\\nâœ… Accuracy: {accuracy*100:.1f}% ({correct}/5)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ğŸ“Š FINAL SCORES FOR SUBMISSION\")\n",
        "print(\"=\"*70)\n",
        "for r in results:\n",
        "    verdict = r.get('analysis', {}).get('human_verdict', 'unknown')\n",
        "    print(f\"{r['file']}: {r['score']:.2f} ({verdict})\")\n",
        "\n",
        "print(f\"\\nğŸ“Š Scores List: {[round(s, 2) for s in scores]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7Q1fJw7q5O0",
        "outputId": "7f8cdd7a-e960-41a3-be2b-b61633b3e89b"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Connected to MCP Server. Available tools: ['search_facebook_users', 'get_facebook_profile', 'get_facebook_mutual_friends', 'search_linkedin_people', 'get_linkedin_profile', 'get_linkedin_interactions']\n",
            "\n",
            "ğŸš€ Starting CV Verification System\n",
            "ğŸ“Š Processing 5 CVs...\n",
            "\n",
            "\n",
            "======================================================================\n",
            "ğŸ“ CV 1: CV_1.pdf\n",
            "======================================================================\n",
            "\n",
            "  ğŸ“„ [Step 1] Parsing CV text...\n",
            "    âœ… Extracted: John Smith - 1 jobs, 1 degrees\n",
            "\n",
            "  ğŸ” [Step 2] Searching LinkedIn for John Smith...\n",
            "\n",
            "    ğŸ“‹ CV Context Analysis:\n",
            "      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
            "      â”‚ Companies: ['bytedance']\n",
            "      â”‚ Schools:   ['mcgill university']\n",
            "      â”‚ Location:  singapore, singapore\n",
            "      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\n",
            "    ğŸ” Searching with name\n",
            "      â†’ Found 20 profiles\n",
            "\n",
            "    ğŸ“Š Evaluating top 5 profiles...\n",
            "      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
            "      â”‚ [1/5] Checking John Smith           - Finance Professional                    \n",
            "      â”‚   ğŸ“Š Match Score: 0 (C:0 + S:0 + L:0)\n",
            "      â”‚ [2/5] Checking John Smith           - Marketing Professional                  \n",
            "      â”‚   âœ“ Company: 'bytedance' matches LinkedIn\n",
            "      â”‚   âœ“ School:  'mcgill university' matches LinkedIn\n",
            "      â”‚   ğŸ“Š Match Score: 5 (C:3 + S:2 + L:0)\n",
            "      â”‚ [3/5] Checking John Smith           - Logistics Professional                  \n",
            "      â”‚   ğŸ“Š Match Score: 0 (C:0 + S:0 + L:0)\n",
            "      â”‚ [4/5] Checking John Smith           - Logistics Professional                  \n",
            "      â”‚   ğŸ“Š Match Score: 0 (C:0 + S:0 + L:0)\n",
            "      â”‚ [5/5] Checking John Smith           - Marketing Professional                  \n",
            "      â”‚   âœ“ School:  'mcgill university' matches LinkedIn\n",
            "      â”‚   ğŸ“Š Match Score: 2 (C:0 + S:2 + L:0)\n",
            "      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\n",
            "    ğŸ† Best Match Selected:\n",
            "      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
            "      â”‚ Name:     John Smith\n",
            "      â”‚ Headline: Marketing Professional\n",
            "      â”‚ Match Score: 5/10\n",
            "      â”‚ Company Matches: ['bytedance']\n",
            "      â”‚ School Matches:  ['mcgill university']\n",
            "      â”‚ Location Match:  False\n",
            "      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "      Verdict: âœ… Strong match - highly likely the same person\n",
            "\n",
            "  ğŸ§  [Step 3] LLM Human-Like Analysis...\n",
            "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
            "    â”‚ Starting detailed comparison...                                â”‚\n",
            "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\n",
            "    ğŸ’­ LLM is now thinking like a human...\n",
            "\n",
            "    ğŸ“ LLM Reasoning Process:\n",
            "      1.  **Name Comparison:** The full name 'John Smith' matches perfectly on both documents. This is a strong initial indicator of the same person. \n",
            "      2.  **Location Comparison:** The location 'Singapore, Singapore' on the CV matches the city and country 'Singapore' on LinkedIn. This is a perfect match. \n",
            "      3.  **Education Comparison:** The institution 'McGill University' matches exactly. The degree 'Bachelor of Science (BSc) in Marketing' on the CV is fully consistent with 'BSc' and 'Marketing' on LinkedIn. The graduation year '2009' also matches perfectly. This section is a perfect match. \n",
            "      4.  **Work Experience Comparison:** The company 'ByteDance', title 'Engineer', and start year '2020' all match perfectly. However, the CV states 'Present' for the end date, implying current employment, while LinkedIn explicitly states `is_current: false`. This is a critical and direct contradiction. A human recruiter would view this as a significant discrepancy regarding the individual's current employment status. \n",
            "      5.  **Skills Comparison:** All three listed skills ('Content Creation', 'SEO', 'Social Media') are present on both documents, indicating consistency in reported abilities. \n",
            "      6.  **Overall Judgment:** While there are numerous strong matches across name, location, education, skills, and the core details of the work experience (company, title, start year), the direct contradiction regarding current employment at ByteDance is a major red flag. It suggests either an outdated CV or an attempt to misrepresent current employment. Despite this significant discrepancy, the sheer volume of other matching data points makes it highly probable that it is the same person, but with a critical inconsistency that would require immediate clarification. This falls into the 'Fair match' category.\n",
            "\n",
            "    ğŸ“Š Final Score: 0.65\n",
            "    ğŸ·ï¸  Human Verdict: probably_same_person\n",
            "\n",
            "    âœ… What matches:\n",
            "      â€¢ Full Name: John Smith\n",
            "      â€¢ Location: Singapore, Singapore\n",
            "      â€¢ Education Institution: McGill University\n",
            "      â€¢ Education Degree: Bachelor of Science (BSc) in Marketing (substantially matching)\n",
            "      â€¢ Education End Year: 2009\n",
            "      â€¢ Work Experience Company: ByteDance\n",
            "      â€¢ Work Experience Title: Engineer\n",
            "      â€¢ Work Experience Start Year: 2020\n",
            "      â€¢ Skills: Content Creation\n",
            "      â€¢ Skills: SEO\n",
            "      â€¢ Skills: Social Media\n",
            "\n",
            "    âŒ What doesn't match:\n",
            "      â€¢ The CV states 'Present' for the ByteDance work experience end date, while the LinkedIn profile states `is_current: false` for the same role, indicating the person is not currently employed there. This is a direct contradiction regarding current employment status.\n",
            "\n",
            "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "    FINAL VERDICT: Score = 0.65 | probably_same_person\n",
            "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "======================================================================\n",
            "ğŸ“ CV 2: CV_2.pdf\n",
            "======================================================================\n",
            "\n",
            "  ğŸ“„ [Step 1] Parsing CV text...\n",
            "    âœ… Extracted: Minh Pham - 2 jobs, 1 degrees\n",
            "\n",
            "  ğŸ” [Step 2] Searching LinkedIn for Minh Pham...\n",
            "\n",
            "    ğŸ“‹ CV Context Analysis:\n",
            "      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
            "      â”‚ Companies: ['bcg', 'tencent']\n",
            "      â”‚ Schools:   ['the university of hong kong']\n",
            "      â”‚ Location:  beijing, china\n",
            "      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\n",
            "    ğŸ” Searching with name\n",
            "      â†’ Found 20 profiles\n",
            "\n",
            "    ğŸ“Š Evaluating top 5 profiles...\n",
            "      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
            "      â”‚ [1/5] Checking Minh Pham            - Design Professional                     \n",
            "      â”‚   âœ“ Company: 'bcg' matches LinkedIn\n",
            "      â”‚   âœ“ Company: 'tencent' matches LinkedIn\n",
            "      â”‚   âœ“ School:  'the university of hong kong' matches LinkedIn\n",
            "      â”‚   ğŸ“Š Match Score: 8 (C:6 + S:2 + L:0)\n",
            "      â”‚ [2/5] Checking Minh Pham            - Logistics Professional                  \n",
            "      â”‚   ğŸ“Š Match Score: 0 (C:0 + S:0 + L:0)\n",
            "      â”‚ [3/5] Checking Minh Pham            - AI Professional                         \n",
            "      â”‚   ğŸ“Š Match Score: 0 (C:0 + S:0 + L:0)\n",
            "      â”‚ [4/5] Checking Minh Pham            - Logistics Professional                  \n",
            "      â”‚   ğŸ“Š Match Score: 0 (C:0 + S:0 + L:0)\n",
            "      â”‚ [5/5] Checking Minh Pham            - Logistics Professional                  \n",
            "      â”‚   ğŸ“Š Match Score: 0 (C:0 + S:0 + L:0)\n",
            "      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\n",
            "    ğŸ† Best Match Selected:\n",
            "      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
            "      â”‚ Name:     Minh Pham\n",
            "      â”‚ Headline: Design Professional\n",
            "      â”‚ Match Score: 8/10\n",
            "      â”‚ Company Matches: ['bcg', 'tencent']\n",
            "      â”‚ School Matches:  ['the university of hong kong']\n",
            "      â”‚ Location Match:  False\n",
            "      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "      Verdict: âœ… Strong match - highly likely the same person\n",
            "\n",
            "  ğŸ§  [Step 3] LLM Human-Like Analysis...\n",
            "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
            "    â”‚ Starting detailed comparison...                                â”‚\n",
            "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\n",
            "    ğŸ’­ LLM is now thinking like a human...\n",
            "\n",
            "    ğŸ“ LLM Reasoning Process:\n",
            "      As a human expert, I would first check the name and location for an immediate match, which they are. Then, I'd move to education and work experience, which are the most critical sections. For education, the institution, degree, and graduation year are identical. LinkedIn simply provides more detail (start year, field breakdown) which is consistent. For work experience, both companies, titles, and dates are exact matches. LinkedIn adds 'seniority', which is an additional piece of information, not a contradiction. Skills are also largely consistent, with minor wording for one and LinkedIn adding proficiency. All key information aligns perfectly, and the minor differences are either additional details or slight formatting variations, which are very common between a CV and a LinkedIn profile. There are no contradictions or significant gaps.\n",
            "\n",
            "    ğŸ“Š Final Score: 0.95\n",
            "    ğŸ·ï¸  Human Verdict: clearly_same_person\n",
            "\n",
            "    âœ… What matches:\n",
            "      â€¢ Full Name: Minh Pham\n",
            "      â€¢ Location: Beijing, China\n",
            "      â€¢ Educational Institution: The University of Hong Kong\n",
            "      â€¢ Educational Degree: BSc in Design (or equivalent breakdown)\n",
            "      â€¢ Educational End Year: 2011\n",
            "      â€¢ Work Experience 1 Company: BCG\n",
            "      â€¢ Work Experience 1 Title: Manager\n",
            "      â€¢ Work Experience 1 Start Year: 2022\n",
            "      â€¢ Work Experience 1 End Year: Present/Current\n",
            "      â€¢ Work Experience 2 Company: Tencent\n",
            "      â€¢ Work Experience 2 Title: Analyst\n",
            "      â€¢ Work Experience 2 Start Year: 2013\n",
            "      â€¢ Work Experience 2 End Year: 2017\n",
            "      â€¢ Skills: Prototyping, Graphic Design, UI/UX (with minor wording variation)\n",
            "\n",
            "    âŒ What doesn't match:\n",
            "      â€¢ LinkedIn profile includes 'seniority: junior' for both work experience entries, which is not present on the CV.\n",
            "      â€¢ LinkedIn education entry includes a 'start_year' (2007) which is not explicitly on the CV, though the end year matches.\n",
            "      â€¢ LinkedIn skills list 'UI/UX' while CV lists 'UI/UX Design' (minor wording difference).\n",
            "      â€¢ LinkedIn skills include proficiency levels, which are not on the CV.\n",
            "\n",
            "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "    FINAL VERDICT: Score = 0.95 | clearly_same_person\n",
            "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "======================================================================\n",
            "ğŸ“ CV 3: CV_3.pdf\n",
            "======================================================================\n",
            "\n",
            "  ğŸ“„ [Step 1] Parsing CV text...\n",
            "    âœ… Extracted: Wei Zhang - 1 jobs, 1 degrees\n",
            "\n",
            "  ğŸ” [Step 2] Searching LinkedIn for Wei Zhang...\n",
            "\n",
            "    ğŸ“‹ CV Context Analysis:\n",
            "      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
            "      â”‚ Companies: ['pwc']\n",
            "      â”‚ Schools:   ['university of tokyo']\n",
            "      â”‚ Location:  munich, germany\n",
            "      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\n",
            "    ğŸ” Searching with name\n",
            "      â†’ Found 20 profiles\n",
            "\n",
            "    ğŸ“Š Evaluating top 5 profiles...\n",
            "      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
            "      â”‚ [1/5] Checking Wei Zhang            - Legal Professional                      \n",
            "      â”‚   ğŸ“Š Match Score: 0 (C:0 + S:0 + L:0)\n",
            "      â”‚ [2/5] Checking Wei Zhang            - Education Professional                  \n",
            "      â”‚   ğŸ“Š Match Score: 0 (C:0 + S:0 + L:0)\n",
            "      â”‚ [3/5] Checking Wei Zhang            - Design Professional                     \n",
            "      â”‚   ğŸ“Š Match Score: 0 (C:0 + S:0 + L:0)\n",
            "      â”‚ [4/5] Checking Wei Zhang            - Consulting Professional                 \n",
            "      â”‚   âœ“ Company: 'pwc' matches LinkedIn\n",
            "      â”‚   âœ“ School:  'university of tokyo' matches LinkedIn\n",
            "      â”‚   ğŸ“Š Match Score: 5 (C:3 + S:2 + L:0)\n",
            "      â”‚ [5/5] Checking Wei Zhang            - Finance Professional                    \n",
            "      â”‚   ğŸ“Š Match Score: 0 (C:0 + S:0 + L:0)\n",
            "      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\n",
            "    ğŸ† Best Match Selected:\n",
            "      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
            "      â”‚ Name:     Wei Zhang\n",
            "      â”‚ Headline: Consulting Professional\n",
            "      â”‚ Match Score: 5/10\n",
            "      â”‚ Company Matches: ['pwc']\n",
            "      â”‚ School Matches:  ['university of tokyo']\n",
            "      â”‚ Location Match:  False\n",
            "      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "      Verdict: âœ… Strong match - highly likely the same person\n",
            "\n",
            "  ğŸ§  [Step 3] LLM Human-Like Analysis...\n",
            "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
            "    â”‚ Starting detailed comparison...                                â”‚\n",
            "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\n",
            "    ğŸ’­ LLM is now thinking like a human...\n",
            "\n",
            "    ğŸ“ LLM Reasoning Process:\n",
            "      As a human expert, I first compare the core identifying information. The full name, location, education institution, degree, and graduation year all match perfectly. The work experience company, title, and start year also align. These strong matches overwhelmingly suggest it is the same individual. However, a critical discrepancy arises in the work experience end date/current status. The CV claims 'Present' employment at PwC, while the LinkedIn profile explicitly states `is_current: false` for that role. This is a fundamental contradiction regarding current employment status, which is a major red flag for a recruiter. While many elements match, this significant inconsistency prevents a high score. It's not a complete mismatch because so much *does* align, but it's more than a minor difference. A recruiter would flag this for clarification. Therefore, it falls into the 'Fair match' category, indicating noticeable discrepancies but still probably the same person, requiring further investigation.\n",
            "\n",
            "    ğŸ“Š Final Score: 0.65\n",
            "    ğŸ·ï¸  Human Verdict: probably_same_person\n",
            "\n",
            "    âœ… What matches:\n",
            "      â€¢ Full Name: Wei Zhang\n",
            "      â€¢ Location: Munich, Germany\n",
            "      â€¢ Education Institution: University of Tokyo\n",
            "      â€¢ Education Degree: BSc in Consulting (or equivalent breakdown)\n",
            "      â€¢ Education End Year: 2015\n",
            "      â€¢ Work Experience Company: PwC\n",
            "      â€¢ Work Experience Title: Engineer\n",
            "      â€¢ Work Experience Start Year: 2013\n",
            "      â€¢ Skills: Data Analysis, PowerPoint, Problem Solving (with varying proficiency indicated on LinkedIn)\n",
            "\n",
            "    âŒ What doesn't match:\n",
            "      â€¢ Work experience end date/current status: CV states 'Present' (currently employed), while LinkedIn states `is_current: false` (not currently employed) for the PwC role.\n",
            "      â€¢ Skills list: CV lists 'Analytical' and 'Business Strategy' which are not explicitly on LinkedIn (though 'Strategy' is present). LinkedIn lists proficiency levels for skills, which the CV does not.\n",
            "\n",
            "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "    FINAL VERDICT: Score = 0.65 | probably_same_person\n",
            "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "======================================================================\n",
            "ğŸ“ CV 4: CV_4.pdf\n",
            "======================================================================\n",
            "\n",
            "  ğŸ“„ [Step 1] Parsing CV text...\n",
            "    âœ… Extracted: Rahul Sharma - 2 jobs, 1 degrees\n",
            "\n",
            "  ğŸ” [Step 2] Searching LinkedIn for Rahul Sharma...\n",
            "\n",
            "    ğŸ“‹ CV Context Analysis:\n",
            "      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
            "      â”‚ Companies: ['microsoft', 'startupxyz']\n",
            "      â”‚ Schools:   ['tsinghua university']\n",
            "      â”‚ Location:  singapore\n",
            "      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\n",
            "    ğŸ” Searching with name\n",
            "      â†’ Found 20 profiles\n",
            "\n",
            "    ğŸ“Š Evaluating top 5 profiles...\n",
            "      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
            "      â”‚ [1/5] Checking Rahul Sharma         - Education Professional                  \n",
            "      â”‚   ğŸ“Š Match Score: 0 (C:0 + S:0 + L:0)\n",
            "      â”‚ [2/5] Checking Rahul Sharma         - Legal Professional                      \n",
            "      â”‚   ğŸ“Š Match Score: 0 (C:0 + S:0 + L:0)\n",
            "      â”‚ [3/5] Checking Rahul Sharma         - Logistics Professional                  \n",
            "      â”‚   ğŸ“Š Match Score: 0 (C:0 + S:0 + L:0)\n",
            "      â”‚ [4/5] Checking Rahul Sharma         - Software Professional                   \n",
            "      â”‚   ğŸ“Š Match Score: 0 (C:0 + S:0 + L:0)\n",
            "      â”‚ [5/5] Checking Rahul Sharma         - Software Professional                   \n",
            "      â”‚   ğŸ“Š Match Score: 0 (C:0 + S:0 + L:0)\n",
            "      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\n",
            "    ğŸ† Best Match Selected:\n",
            "      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
            "      â”‚ Name:     Rahul Sharma\n",
            "      â”‚ Headline: Education Professional\n",
            "      â”‚ Match Score: 0/10\n",
            "      â”‚ Company Matches: []\n",
            "      â”‚ School Matches:  []\n",
            "      â”‚ Location Match:  False\n",
            "      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "      Verdict: âŒ Weak match - likely different person with same name\n",
            "\n",
            "  ğŸ§  [Step 3] LLM Human-Like Analysis...\n",
            "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
            "    â”‚ Starting detailed comparison...                                â”‚\n",
            "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\n",
            "    âš ï¸ Match score too low (0) - likely wrong person\n",
            "\n",
            "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "    FINAL VERDICT: Score = 0.00 | unknown\n",
            "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "======================================================================\n",
            "ğŸ“ CV 5: CV_5.pdf\n",
            "======================================================================\n",
            "\n",
            "  ğŸ“„ [Step 1] Parsing CV text...\n",
            "    âœ… Extracted: Rahul Sharma - 4 jobs, 1 degrees\n",
            "\n",
            "  ğŸ” [Step 2] Searching LinkedIn for Rahul Sharma...\n",
            "\n",
            "    ğŸ“‹ CV Context Analysis:\n",
            "      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
            "      â”‚ Companies: ['ey', 'startupxyz', 'dataforge', 'urbanflow']\n",
            "      â”‚ Schools:   ['university of tokyo']\n",
            "      â”‚ Location:  london\n",
            "      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\n",
            "    ğŸ” Searching with name\n",
            "      â†’ Found 20 profiles\n",
            "\n",
            "    ğŸ“Š Evaluating top 5 profiles...\n",
            "      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
            "      â”‚ [1/5] Checking Rahul Sharma         - Education Professional                  \n",
            "      â”‚   ğŸ“Š Match Score: 0 (C:0 + S:0 + L:0)\n",
            "      â”‚ [2/5] Checking Rahul Sharma         - Legal Professional                      \n",
            "      â”‚   ğŸ“Š Match Score: 0 (C:0 + S:0 + L:0)\n",
            "      â”‚ [3/5] Checking Rahul Sharma         - Logistics Professional                  \n",
            "      â”‚   âœ“ Location: 'london' matches 'london, uk'\n",
            "      â”‚   ğŸ“Š Match Score: 1 (C:0 + S:0 + L:1)\n",
            "      â”‚ [4/5] Checking Rahul Sharma         - Software Professional                   \n",
            "      â”‚   âœ“ Company: 'ey' matches LinkedIn\n",
            "      â”‚   ğŸ“Š Match Score: 3 (C:3 + S:0 + L:0)\n",
            "      â”‚ [5/5] Checking Rahul Sharma         - Software Professional                   \n",
            "      â”‚   âœ“ Company: 'ey' matches LinkedIn\n",
            "      â”‚   ğŸ“Š Match Score: 3 (C:3 + S:0 + L:0)\n",
            "      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\n",
            "    ğŸ† Best Match Selected:\n",
            "      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
            "      â”‚ Name:     Rahul Sharma\n",
            "      â”‚ Headline: Software Professional\n",
            "      â”‚ Match Score: 3/10\n",
            "      â”‚ Company Matches: ['ey']\n",
            "      â”‚ School Matches:  []\n",
            "      â”‚ Location Match:  False\n",
            "      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "      Verdict: âš ï¸ Partial match - possibly the same person\n",
            "\n",
            "  ğŸ§  [Step 3] LLM Human-Like Analysis...\n",
            "    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
            "    â”‚ Starting detailed comparison...                                â”‚\n",
            "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
            "\n",
            "    ğŸ’­ LLM is now thinking like a human...\n",
            "\n",
            "    ğŸ“ LLM Reasoning Process:\n",
            "      As a human expert, I would first check the name, which matches. However, this is often the only commonality for different individuals with common names. I then proceed to compare the substantive professional and personal details. \n",
            "      1.  **Education:** The institutions, specific degree fields, and completion years are completely different. This is a major red flag.\n",
            "      2.  **Work Experience:** None of the companies, job titles, or employment periods overlap. The LinkedIn experience dates are also highly unusual (e.g., a future end date, or a null end date marked as not current), which further suggests a different profile or significant data discrepancies.\n",
            "      3.  **Location:** London vs. Hong Kong is a clear mismatch.\n",
            "      4.  **Skills:** The skill sets are entirely different, one focusing on AI/ML/NLP and the other on DevOps/backend technologies. While a person can have diverse skills, there's no overlap in the listed ones.\n",
            "      Given that the only matching piece of information is the full name, and all other critical professional and personal details are entirely different, it is highly improbable that these two profiles belong to the same individual. The discrepancies are too numerous and significant to be considered minor errors or omissions.\n",
            "\n",
            "    ğŸ“Š Final Score: 0.05\n",
            "    ğŸ·ï¸  Human Verdict: clearly_different\n",
            "\n",
            "    âœ… What matches:\n",
            "      â€¢ Full Name: Rahul Sharma\n",
            "\n",
            "    âŒ What doesn't match:\n",
            "      â€¢ Education institution (University of Tokyo vs HKUST)\n",
            "      â€¢ Education degree field (Artificial Intelligence vs Software)\n",
            "      â€¢ Education completion years (2012 vs 2006)\n",
            "      â€¢ All work experience companies (EY, StartupXYZ, DataForge, UrbanFlow vs McKinsey, Gojek)\n",
            "      â€¢ All work experience job titles\n",
            "      â€¢ All work experience dates and current status\n",
            "      â€¢ Location (London vs Hong Kong)\n",
            "      â€¢ Skills listed (Machine Learning/AI/NLP vs Kubernetes/Go/Docker)\n",
            "\n",
            "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "    FINAL VERDICT: Score = 0.05 | clearly_different\n",
            "    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "\n",
            "âœ… Detailed report saved to verification_report.md\n",
            "\n",
            "======================================================================\n",
            "ğŸ“Š EVALUATION RESULTS\n",
            "======================================================================\n",
            "CV_1: CV_1.pdf\n",
            "   Score: 0.65 | Pred: 1 | Truth: 1 âœ“\n",
            "   Verdict: probably_same_person\n",
            "\n",
            "CV_2: CV_2.pdf\n",
            "   Score: 0.95 | Pred: 1 | Truth: 1 âœ“\n",
            "   Verdict: clearly_same_person\n",
            "\n",
            "CV_3: CV_3.pdf\n",
            "   Score: 0.65 | Pred: 1 | Truth: 1 âœ“\n",
            "   Verdict: probably_same_person\n",
            "\n",
            "CV_4: CV_4.pdf\n",
            "   Score: 0.00 | Pred: 0 | Truth: 0 âœ“\n",
            "   Verdict: unknown\n",
            "\n",
            "CV_5: CV_5.pdf\n",
            "   Score: 0.05 | Pred: 0 | Truth: 0 âœ“\n",
            "   Verdict: clearly_different\n",
            "\n",
            "\n",
            "âœ… Accuracy: 100.0% (5/5)\n",
            "\n",
            "======================================================================\n",
            "ğŸ“Š FINAL SCORES FOR SUBMISSION\n",
            "======================================================================\n",
            "CV_1.pdf: 0.65 (probably_same_person)\n",
            "CV_2.pdf: 0.95 (clearly_same_person)\n",
            "CV_3.pdf: 0.65 (probably_same_person)\n",
            "CV_4.pdf: 0.00 (unknown)\n",
            "CV_5.pdf: 0.05 (clearly_different)\n",
            "\n",
            "ğŸ“Š Scores List: [0.65, 0.95, 0.65, 0.0, 0.05]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation code\n",
        "\n",
        "In the test phase, you will be given 5 CV files with fixed names:\n",
        "\n",
        "    CV_1.pdf, CV_2.pdf, CV_3.pdf, CV_4.pdf, CV_5.pdf\n",
        "\n",
        "Your system must process these CVs and output a list of 5 scores,\n",
        "one score per CV, in the same order:\n",
        "\n",
        "    scores = [s1, s2, s3, s4, s5]\n",
        "\n",
        "Each score must be a float in the range [0, 1], representing the\n",
        "reliability or confidence that the CV is valid (or meets the task criteria).\n",
        "\n",
        "The ground-truth labels are binary:\n",
        "\n",
        "    groundtruth = [0 or 1, ..., 0 or 1]\n",
        "\n",
        "Each CV is evaluated independently using a threshold of 0.5:\n",
        "\n",
        "- If score > 0.5 and groundtruth == 1 â†’ Full credit\n",
        "- If score â‰¤ 0.5 and groundtruth == 0 â†’ Full credit\n",
        "- Otherwise â†’ No credit\n",
        "\n",
        "In other words, 0.5 is the decision threshold.\n",
        "\n",
        "- Each CV contributes equally.\n",
        "- Final score = (number of correct decisions) / 5\n"
      ],
      "metadata": {
        "id": "UqO99iOlq6mc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================\n",
        "#  Evaluation code\n",
        "# =====================================================\n",
        "\n",
        "def evaluate(scores, groundtruth, threshold=0.5):\n",
        "    \"\"\"\n",
        "    scores: list of floats in [0, 1], length = 5\n",
        "    groundtruth: list of ints (0 or 1), length = 5\n",
        "    \"\"\"\n",
        "    assert len(scores) == 5\n",
        "    assert len(groundtruth) == 5\n",
        "\n",
        "    correct = 0\n",
        "    decisions = []\n",
        "\n",
        "    for s, gt in zip(scores, groundtruth):\n",
        "        pred = 1 if s > threshold else 0\n",
        "        decisions.append(pred)\n",
        "        if pred == gt:\n",
        "            correct += 1\n",
        "\n",
        "    final_score = correct / len(scores)\n",
        "\n",
        "    return {\n",
        "        \"decisions\": decisions,\n",
        "        \"correct\": correct,\n",
        "        \"total\": len(scores),\n",
        "        \"final_score\": final_score\n",
        "    }\n"
      ],
      "metadata": {
        "id": "0TtL07airIqz"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = [0.65, 0.95, 0.65, 0.0, 0.05] # Your code should generate this list [0.2, 0.3, 0.4, 0.5, 0.6]\n",
        "groundtruth = [1, 1, 1, 0, 0] # Do not modify\n",
        "\n",
        "result = evaluate(scores, groundtruth)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J14ltXjPtaMF",
        "outputId": "2fa4afda-c687-4722-e516-58d4fc23c1c9"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'decisions': [1, 1, 1, 0, 0], 'correct': 5, 'total': 5, 'final_score': 1.0}\n"
          ]
        }
      ]
    }
  ]
}